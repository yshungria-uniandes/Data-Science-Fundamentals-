{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kemjtjo2NPtk"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yshungria-uniandes/Data-Science-Fundamentals-/blob/main/Ejemplo_Proyecto_1_Parte_1_(Core)_22_11_2024_SOLUCI%C3%93N.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1- Preprocesamiento Básico con numpy**"
      ],
      "metadata": {
        "id": "kemjtjo2NPtk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**a) Leer y procesar los datos**"
      ],
      "metadata": {
        "id": "RK6A5uLONd0I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**a.1) Leer y cargar data set desde un CSV**"
      ],
      "metadata": {
        "id": "jpE5Y9vgRInC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KXt4omerQN3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeUe-HbCL7hH",
        "outputId": "74cb1890-1157-47b1-f63a-3979bc724fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombres de las columnas: ('Transaction_ID', 'Date', 'Customer_ID', 'Gender', 'Age', 'Product_Category', 'Quantity', 'Price_per_Unit', 'Total_Amount')\n",
            "\n",
            "Datos del dataset:\n",
            "[(1, '2023-11-24', 'CUST001', 'Male', 34, 'Beauty', 3,  50,  150)\n",
            " (2, '2023-02-27', 'CUST002', 'Female', 26, 'Clothing', 2, 500, 1000)\n",
            " (3, '2023-01-13', 'CUST003', 'Male', 50, 'Electronics', 1,  30,   30)\n",
            " (4, '2023-05-21', 'CUST004', 'Male', 37, 'Clothing', 1, 500,  500)\n",
            " (5, '2023-05-06', 'CUST005', 'Male', 30, 'Beauty', 2,  50,  100)]\n"
          ]
        }
      ],
      "source": [
        "# Importamos la librería numpy, que es útil para trabajar con matrices y datos numéricos\n",
        "import numpy as np\n",
        "\n",
        "# Leemos el archivo CSV utilizando la función 'genfromtxt' de numpy.\n",
        "# Especificamos que el archivo está delimitado por comas, y que los datos tienen nombres de columna en la primera fila.\n",
        "# 'dtype=None' permite que numpy infiera el tipo de datos automáticamente.\n",
        "# 'encoding=\"utf-8\"' asegura que se manejen correctamente los caracteres especiales (como acentos).\n",
        "# 'names=True' asegura que la primera fila se utilice como los nombres de las columnas.\n",
        "data_csv = np.genfromtxt('/content/retail_sales_dataset.csv', delimiter=',', dtype=None, encoding='utf-8', names=True)\n",
        "\n",
        "# Mostramos los nombres de las columnas en el dataset utilizando 'dtype.names', que es un atributo del objeto numpy estructurado.\n",
        "# Este atributo nos da los nombres de las columnas leídas en el archivo CSV.\n",
        "print(\"Nombres de las columnas:\", data_csv.dtype.names)\n",
        "\n",
        "# Mostramos los primeros 5 registros del dataset usando 'data_csv[:5]'.\n",
        "# Esto nos permite ver una muestra de los datos cargados, pero limitando la salida a las primeras 5 filas.\n",
        "print(\"\\nDatos del dataset:\")\n",
        "print(data_csv[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**a.2)  Leer y cargar data set desde un TXT**"
      ],
      "metadata": {
        "id": "PuU6e97wTgZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos la librería numpy, que es útil para trabajar con arrays y manejar datos numéricos.\n",
        "import numpy as np\n",
        "\n",
        "# Ruta del archivo de texto que se va a cargar\n",
        "ruta = '/content/retail_sales_dataset.txt'\n",
        "\n",
        "# Cargamos el archivo de texto utilizando la función 'loadtxt' de numpy.\n",
        "# 'delimiter' especifica que los valores están separados por tabuladores (\\t).\n",
        "# 'skiprows=1' indica que se debe saltar la primera fila (que normalmente contiene el encabezado).\n",
        "# 'dtype=str' asegura que todos los datos se carguen como cadenas de texto (strings), independientemente del tipo de datos original.\n",
        "data_txt = np.loadtxt(ruta, delimiter='\\t', skiprows=1, dtype=str)\n",
        "\n",
        "# Mostramos las primeras 5 filas del dataset cargado para inspeccionar los datos\n",
        "print(data_txt[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zBDT617SbVR",
        "outputId": "767c65c3-749f-4bb9-db32-521cd6de7dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['1' '2023-11-24' 'CUST001' 'Male' '34' 'Beauty' '3' '50' '150']\n",
            " ['2' '2023-02-27' 'CUST002' 'Female' '26' 'Clothing' '2' '500' '1000']\n",
            " ['3' '2023-01-13' 'CUST003' 'Male' '50' 'Electronics' '1' '30' '30']\n",
            " ['4' '2023-05-21' 'CUST004' 'Male' '37' 'Clothing' '1' '500' '500']\n",
            " ['5' '2023-05-06' 'CUST005' 'Male' '30' 'Beauty' '2' '50' '100']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**a.3) Leer y cargar data set desde un JSON**"
      ],
      "metadata": {
        "id": "PfDGtAVITltF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos las librerías necesarias: json para manejar archivos JSON y numpy para trabajar con arrays.\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "# Ruta del archivo JSON\n",
        "ruta = '/content/retail_sales_dataset.json'\n",
        "\n",
        "# Abrimos el archivo JSON en modo lectura ('r') y lo cargamos usando json.load() para convertirlo en un objeto de Python.\n",
        "with open(ruta, 'r') as file:\n",
        "    data_json = json.load(file)\n",
        "\n",
        "# Extraemos las claves (nombres de las columnas) del primer registro del archivo JSON.\n",
        "# Esto asume que todos los registros tienen las mismas claves.\n",
        "columns = list(data_json[0].keys())\n",
        "\n",
        "# Convertimos los datos a un array de NumPy. Para cada entrada (registro) en el archivo JSON,\n",
        "# creamos una lista de valores correspondientes a las claves (columnas) y luego la convertimos a un array.\n",
        "data_json_np = np.array([[entry[col] for col in columns] for entry in data_json])\n",
        "\n",
        "# Mostramos las primeras 5 filas del array de NumPy para inspeccionar los datos convertidos\n",
        "print(data_json_np[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELwZV37fTrW4",
        "outputId": "484c20b9-5d11-4674-80a7-e3f2e0c157fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['1' '2023-11-24' 'CUST001' 'Male' '34' 'Beauty' '3' '50' '150']\n",
            " ['2' '2023-02-27' 'CUST002' 'Female' '26' 'Clothing' '2' '500' '1000']\n",
            " ['3' '2023-01-13' 'CUST003' 'Male' '50' 'Electronics' '1' '30' '30']\n",
            " ['4' '2023-05-21' 'CUST004' 'Male' '37' 'Clothing' '1' '500' '500']\n",
            " ['5' '2023-05-06' 'CUST005' 'Male' '30' 'Beauty' '2' '50' '100']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b) Verificar si hay valores nulos y reemplazarlos**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mzCYgiG5Nirr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.1) Verifir datos nulos dentro del data set**"
      ],
      "metadata": {
        "id": "0QCkwrv2dHBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iteramos sobre cada nombre de columna en el dataset para verificar si hay valores nulos\n",
        "for column in data_csv.dtype.names:\n",
        "    # Comprobamos si la columna tiene tipo de dato 'float' (números decimales)\n",
        "    if data_csv[column].dtype == 'float':\n",
        "        # Si la columna es de tipo float, usamos np.isnan() para contar cuántos valores nulos (NaN) hay en esa columna\n",
        "        print(f\"\\nValores nulos en columna {column}:\", np.sum(np.isnan(data_csv[column])))\n",
        "    else:\n",
        "        # Si la columna no es de tipo float, asumimos que no contiene valores nulos\n",
        "        # (esto puede variar dependiendo del tipo de datos, pero este es un enfoque común)\n",
        "        print(f'No existen datos nulos en la columna {column}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "F_UaL_5fdYLK",
        "outputId": "49fc22cf-e4ab-4b3e-fbc9-da340968692f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data_csv' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-be731f9809a9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Iteramos sobre cada nombre de columna en el dataset para verificar si hay valores nulos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Comprobamos si la columna tiene tipo de dato 'float' (números decimales)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_csv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'float'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Si la columna es de tipo float, usamos np.isnan() para contar cuántos valores nulos (NaN) hay en esa columna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data_csv' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\### **b.2) Cargamos un data set con datos nulos**"
      ],
      "metadata": {
        "id": "JjeFbtwhdITl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el archivo CSV que contiene valores nulos (NaN) en los datos\n",
        "# Usamos np.genfromtxt para leer el archivo, con los siguientes parámetros:\n",
        "# El delimitador es la coma (archivo CSV)\n",
        "# Deja que numpy infiera el tipo de dato para cada columna\n",
        "# Codificación para manejar caracteres especiales\n",
        "# La primera fila del archivo contiene los nombres de las columnas\n",
        "data_csv_nulos = np.genfromtxt('/content/retail_sales_dataset.with-nans.csv', delimiter=',', dtype=None, encoding='utf-8', names=True)\n",
        "\n",
        "# El archivo ahora está cargado en data_csv_nulos y se puede procesar como un array de NumPy"
      ],
      "metadata": {
        "id": "FqPNXK-Ud4kS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "b2bf31e9-e6ae-42c7-f232-8db9eb711a2a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c46a206323c1>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Codificación para manejar caracteres especiales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# La primera fila del archivo contiene los nombres de las columnas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata_csv_nulos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/retail_sales_dataset.with-nans.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# El archivo ahora está cargado en data_csv_nulos y se puede procesar como un array de NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.3) Verificamos datos nulos dentro del data set**"
      ],
      "metadata": {
        "id": "fgSOBK9rdJRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iteramos sobre cada nombre de columna en el dataset para verificar si hay valores nulos\n",
        "for column in data_csv_nulos.dtype.names:\n",
        "    # Comprobamos si la columna tiene tipo de dato 'float' (números decimales)\n",
        "    if data_csv_nulos[column].dtype == 'float':\n",
        "        # Si la columna es de tipo float, usamos np.isnan() para contar cuántos valores nulos (NaN) hay en esa columna\n",
        "        print(f\"\\nValores nulos en columna {column}:\", np.sum(np.isnan(data_csv_nulos[column])))\n",
        "    else:\n",
        "        # Si la columna no es de tipo float, asumimos que no contiene valores nulos\n",
        "        # (esto puede variar dependiendo del tipo de datos, pero este es un enfoque común)\n",
        "        print(f'No existen datos nulos en la columna {column}')"
      ],
      "metadata": {
        "id": "HCiMrTx9eGAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.4) Reemplazar valores nulos por 0**"
      ],
      "metadata": {
        "id": "ksZuX5H-ihiA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos una copia del dataset original para evitar modificar el dataset original directamente\n",
        "data_zero = data_csv_nulos.copy()\n",
        "\n",
        "# Iteramos sobre cada nombre de columna en el dataset para reemplazar valores nulos\n",
        "for column in data_zero.dtype.names:\n",
        "    # Comprobamos si la columna tiene tipo de dato 'float64' (números decimales)\n",
        "    if data_zero[column].dtype == 'float64':  # Verificamos que el tipo de datos sea 'float64'\n",
        "        # Reemplazamos los valores nulos (NaN) por 0 en las columnas de tipo float64\n",
        "        data_zero[column] = np.nan_to_num(data_zero[column], nan=0)\n",
        "\n",
        "# Mostramos el resultado después de reemplazar los valores nulos por 0\n",
        "print(\"Datos después de reemplazar nulos por 0:\")\n",
        "print(data_zero[:5])  # Mostramos las primeras 5 filas para verificar el cambio"
      ],
      "metadata": {
        "id": "50uJ17DQmNLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.5) Eliminar filas con valores nulos**"
      ],
      "metadata": {
        "id": "g3u7A7tTkO4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Seleccionar las columnas que deseas verificar\n",
        "columnas_a_verificar = ['Quantity', 'Price_per_Unit', 'Total_Amount']\n",
        "\n",
        "# Verificar si las columnas existen en data_csv_nulos\n",
        "if all(col in data_csv_nulos.dtype.names for col in columnas_a_verificar):\n",
        "    # Si todas las columnas seleccionadas existen en el dataset\n",
        "\n",
        "    # Crear una máscara booleana para identificar las filas sin valores nulos en las columnas seleccionadas\n",
        "    # np.column_stack agrupa las columnas seleccionadas en una matriz 2D\n",
        "    # np.isnan verifica si hay valores nulos (NaN) en las columnas seleccionadas\n",
        "    # ~np.isnan invierte el resultado, marcando como True las filas sin nulos\n",
        "    # np.all(axis=1) asegura que todas las columnas seleccionadas en cada fila no tengan valores nulos\n",
        "    mascara_sin_nulos = np.all(~np.isnan(np.column_stack([data_csv_nulos[col] for col in columnas_a_verificar])), axis=1)\n",
        "\n",
        "    # Aplicar la máscara al dataset para eliminar las filas con valores nulos en las columnas seleccionadas\n",
        "    data_sin_nulos = data_csv_nulos[mascara_sin_nulos]\n",
        "\n",
        "    # Mostrar las primeras filas del dataset sin nulos\n",
        "    print(data_sin_nulos[:5])\n",
        "else:\n",
        "    # Si alguna de las columnas no existe en el dataset, mostramos un mensaje de error\n",
        "    print(\"Algunas columnas de 'columnas_a_verificar' no existen en data_csv_nulos.\")"
      ],
      "metadata": {
        "id": "GHukvSI0mgIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.6) Reemplazar valores nulos por la media de cada columna**"
      ],
      "metadata": {
        "id": "72ijnvwukU6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Reemplazar valores nulos por la media de cada columna\n",
        "for column in data_csv_nulos.dtype.names:\n",
        "    # Verificar si la columna es de tipo float (números decimales)\n",
        "    if data_csv_nulos[column].dtype.kind == 'f':  # 'f' indica tipo float\n",
        "        # Calcular la media de la columna ignorando los valores nulos (NaN)\n",
        "        mean_value = np.nanmean(data_csv_nulos[column])  # np.nanmean ignora los NaN al calcular la media\n",
        "        # Reemplazar los valores nulos (NaN) por la media calculada\n",
        "        data_csv_nulos[column][np.isnan(data_csv_nulos[column])] = mean_value\n",
        "        print(f\"Valores nulos en la columna {column} reemplazados por la media: {mean_value}\")\n",
        "    else:\n",
        "        # Si la columna no es de tipo numérico, no se realiza el reemplazo\n",
        "        print(f\"La columna {column} no es numérica, no se realiza reemplazo.\")\n",
        "\n",
        "# Mostrar el resultado (primeras filas)\n",
        "print('')\n",
        "print(data_csv_nulos[:5])"
      ],
      "metadata": {
        "id": "7NkShHORmveb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.- **Reemplazar nulos por 0:** Este método itera sobre las columnas del DataFrame y utiliza np.nan_to_num() para reemplazar los valores NaN por 0 en columnas de tipo float64.\n",
        "\n",
        "2.- **Eliminar filas con nulos:** Usamos el método dropna() de pandas para eliminar cualquier fila que contenga valores NaN.\n",
        "\n",
        "3.- **Reemplazar nulos por la media:** Recorremos las columnas numéricas y calculamos la media de cada columna, luego usamos fillna() para reemplazar los valores NaN por la media correspondiente."
      ],
      "metadata": {
        "id": "GhHpZLa5kgWR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Exploración de Datos**"
      ],
      "metadata": {
        "id": "HaS2QlH-NVDL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Calcular el total de ventas por categoría de producto"
      ],
      "metadata": {
        "id": "PvgmShGUNoVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a.1) Agrupación con np.unique y bucles**\n",
        "\n",
        "> Agregar bloque entrecomillado\n",
        "\n"
      ],
      "metadata": {
        "id": "K9PaRovIF0H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener categorías únicas e índices inversos\n",
        "categories, inverse = np.unique(data_csv['Product_Category'], return_inverse=True)\n",
        "# np.unique encuentra todos los valores únicos en la columna 'Product_Category'.\n",
        "# La opción return_inverse=True devuelve un array de índices que mapea cada valor original\n",
        "# a su posición correspondiente en el array de categorías únicas.\n",
        "\n",
        "# Calcular el total de ventas por categoría\n",
        "total_ventas_por_categoria = {\n",
        "    category: np.sum(data_csv['Transaction_ID'][inverse == idx])\n",
        "    for idx, category in enumerate(categories)\n",
        "}\n",
        "# Se crea un diccionario para almacenar el total de ventas por categoría.\n",
        "# - `enumerate(categories)`: Itera sobre cada categoría y su índice correspondiente.\n",
        "# - `inverse == idx`: Crea una máscara booleana que selecciona las filas de 'Transaction_ID'\n",
        "#   donde la categoría coincide con la actual (índice `idx`).\n",
        "# - `np.sum(...)`: Suma los valores de 'Transaction_ID' seleccionados por la máscara,\n",
        "#   lo que da el total de ventas para esa categoría.\n",
        "\n",
        "# Imprimir el total de ventas por categoría\n",
        "print(\"\\nTotal de ventas por categoría:\")\n",
        "print(total_ventas_por_categoria)\n",
        "# Se imprime el diccionario resultante, que muestra cada categoría y su total de ventas."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rd-1Uo7rGReG",
        "outputId": "5f713d63-0fb8-4578-e942-db87a703688e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total de ventas por categoría:\n",
            "{'Beauty': 150864, 'Clothing': 173725, 'Electronics': 175911}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a.2) Uso de np.add.at para acumulación**"
      ],
      "metadata": {
        "id": "8RpNQ8BPF_jQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener categorías únicas e índices inversos\n",
        "categories, inverse = np.unique(data_csv['Product_Category'], return_inverse=True)\n",
        "# 'categories' contiene los valores únicos en 'Product_Category'.\n",
        "# 'inverse' es un array que mapea cada elemento original de 'Product_Category' al índice de su categoría única.\n",
        "\n",
        "# Crear un array para acumular los totales, inicializado en ceros\n",
        "totals = np.zeros(len(categories), dtype=data_csv['Transaction_ID'].dtype)\n",
        "# 'totals' tiene una posición para cada categoría única, donde se almacenará el total de ventas.\n",
        "# El tipo de dato se hereda de 'Transaction_ID' para evitar inconsistencias.\n",
        "\n",
        "# Acumular los valores de 'Transaction_ID' en 'totals' según las categorías (usando 'inverse' como índice)\n",
        "np.add.at(totals, inverse, data_csv['Transaction_ID'])\n",
        "# 'np.add.at' acumula los valores de 'Transaction_ID' en 'totals' según los índices en 'inverse'.\n",
        "# Por cada fila, suma el valor correspondiente al índice de su categoría única.\n",
        "\n",
        "# Crear un diccionario que asocia cada categoría con su total acumulado\n",
        "total_ventas_por_categoria_2 = dict(zip(categories, totals))\n",
        "# 'zip(categories, totals)' combina las categorías con sus totales acumulados.\n",
        "# 'dict' convierte esta combinación en un diccionario.\n",
        "\n",
        "# Imprimir el resultado final\n",
        "print(\"\\nTotal de ventas por categoría:\")\n",
        "print(total_ventas_por_categoria_2)\n",
        "# Muestra cada categoría junto con el total de ventas acumuladas."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ir1SL07TGWYf",
        "outputId": "093493d6-f514-4125-c023-c80e9b727157"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total de ventas por categoría:\n",
            "{'Beauty': 150864, 'Clothing': 173725, 'Electronics': 175911}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**a.3) Vectorización completa con np.bincount**"
      ],
      "metadata": {
        "id": "u1v3bQpqGJIw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener categorías únicas e índices inversos\n",
        "categories, inverse = np.unique(data_csv['Product_Category'], return_inverse=True)\n",
        "# 'categories' contiene los valores únicos en 'Product_Category'.\n",
        "# 'inverse' es un array que mapea cada elemento original de 'Product_Category' al índice de su categoría única.\n",
        "\n",
        "# Calcular el total de ventas por categoría usando np.bincount\n",
        "totals = np.bincount(inverse, weights=data_csv['Transaction_ID'])\n",
        "# 'np.bincount' cuenta la frecuencia o suma los valores (con 'weights') para cada índice único en 'inverse'.\n",
        "# En este caso, suma los valores de 'Transaction_ID' correspondientes a cada categoría única.\n",
        "\n",
        "# Crear un diccionario que asocia cada categoría con su total acumulado\n",
        "total_ventas_por_categoria_3 = dict(zip(categories, totals))\n",
        "# 'zip(categories, totals)' combina las categorías únicas con sus totales acumulados.\n",
        "# 'dict' convierte esta combinación en un diccionario.\n",
        "\n",
        "# Imprimir el resultado final\n",
        "print(\"\\nTotal de ventas por categoría:\")\n",
        "print(total_ventas_por_categoria_3)\n",
        "# Muestra cada categoría junto con el total de ventas acumuladas."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRqC6BNBGgj7",
        "outputId": "53d4a6fc-06e3-4f4b-ce82-160ebd475089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total de ventas por categoría:\n",
            "{'Beauty': 150864.0, 'Clothing': 173725.0, 'Electronics': 175911.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Calcular el promedio de ventas diarias por categoría de producto"
      ],
      "metadata": {
        "id": "FEqwDKJgNqVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.1) Agrupación con np.unique y bucles**"
      ],
      "metadata": {
        "id": "BqtXEyR9HFpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las fechas únicas presentes en los datos\n",
        "dates = np.unique(data_csv['Date'])\n",
        "# 'np.unique' devuelve los valores únicos de la columna 'Date', es decir, todas las fechas representadas en el dataset.\n",
        "\n",
        "# Calcular el total de ventas diarias por categoría\n",
        "ventas_diarias = {}\n",
        "# Se inicializa un diccionario vacío donde se almacenarán las ventas diarias por categoría.\n",
        "\n",
        "# Iteramos sobre cada categoría\n",
        "for category in categories:\n",
        "    # Filtrar las ventas de la categoría actual\n",
        "    ventas_por_categoria = data_csv['Total_Amount'][data_csv['Product_Category'] == category]\n",
        "    # 'ventas_por_categoria' almacena las ventas de la categoría actual filtradas por 'Product_Category'.\n",
        "\n",
        "    # Filtrar las fechas asociadas a la categoría actual\n",
        "    fechas_categoria = data_csv['Date'][data_csv['Product_Category'] == category]\n",
        "    # 'fechas_categoria' almacena las fechas correspondientes a la categoría actual.\n",
        "\n",
        "    # Calcular el total de ventas por fecha para esta categoría\n",
        "    ventas_diarias[category] = {fecha: np.sum(ventas_por_categoria[fechas_categoria == fecha]) for fecha in dates}\n",
        "    # Se crea un diccionario dentro de 'ventas_diarias' donde la clave es la fecha y el valor es la suma de ventas para esa fecha\n",
        "    # en la categoría actual. 'fechas_categoria == fecha' selecciona las ventas de esa fecha específica.\n",
        "\n",
        "# Calcular el promedio de ventas diarias por categoría\n",
        "promedio_ventas_diarias = {category: np.mean(list(d.values())) for category, d in ventas_diarias.items()}\n",
        "# Para cada categoría, calculamos el promedio de ventas diarias usando 'np.mean' sobre los valores de ventas diarias en 'ventas_diarias'.\n",
        "# 'list(d.values())' convierte los valores del diccionario en una lista de ventas diarias para calcular el promedio.\n",
        "\n",
        "# Imprimir el resultado del promedio de ventas diarias por categoría\n",
        "print(\"\\nPromedio de ventas diarias por categoría:\")\n",
        "print(promedio_ventas_diarias)\n",
        "# Se imprime el diccionario que contiene los promedios de ventas diarias por categoría."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEi6ZvEQNq4x",
        "outputId": "b20b351f-b572-4687-e8f9-ac0855e682ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Promedio de ventas diarias por categoría:\n",
            "{'Beauty': 415.9855072463768, 'Clothing': 450.95652173913044, 'Electronics': 454.7971014492754}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.2) Uso de np.add.at**"
      ],
      "metadata": {
        "id": "ChNhaZlcHtac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar un diccionario vacío para almacenar las ventas diarias por categoría\n",
        "ventas_diarias = {}\n",
        "\n",
        "# Iterar sobre cada categoría\n",
        "for category in categories:\n",
        "    # Filtrar por categoría\n",
        "    mask_categoria = data_csv['Product_Category'] == category\n",
        "    ventas_por_categoria = data_csv['Total_Amount'][mask_categoria]\n",
        "    fechas_categoria = data_csv['Date'][mask_categoria]\n",
        "\n",
        "    # Obtener fechas únicas e índices inversos\n",
        "    unique_dates, inverse = np.unique(fechas_categoria, return_inverse=True)\n",
        "    # 'unique_dates' contiene las fechas únicas de la categoría actual.\n",
        "    # 'inverse' es un array que mapea cada fecha en 'fechas_categoria' al índice de su fecha única.\n",
        "\n",
        "    # Inicializar un acumulador para las ventas diarias, con un valor inicial de cero\n",
        "    ventas = np.zeros(len(unique_dates), dtype=ventas_por_categoria.dtype)\n",
        "    # 'ventas' es un array donde se acumularán las ventas diarias por cada fecha única.\n",
        "\n",
        "    # Acumular las ventas por fecha utilizando np.add.at\n",
        "    np.add.at(ventas, inverse, ventas_por_categoria)\n",
        "    # 'np.add.at' acumula los valores de 'ventas_por_categoria' en el array 'ventas' según los índices de 'inverse'.\n",
        "\n",
        "    # Guardar las ventas diarias en un diccionario, donde la clave es la fecha y el valor es el total de ventas\n",
        "    ventas_diarias[category] = dict(zip(unique_dates, ventas))\n",
        "    # 'zip' asocia cada fecha única con el total de ventas correspondiente, y 'dict' lo convierte en un diccionario.\n",
        "\n",
        "# Calcular el promedio de ventas diarias por categoría\n",
        "promedio_ventas_diarias = {category: np.mean(list(d.values())) for category, d in ventas_diarias.items()}\n",
        "# Para cada categoría, se calcula el promedio de las ventas diarias usando 'np.mean' sobre los valores del diccionario 'ventas_diarias'.\n",
        "\n",
        "# Imprimir el resultado de los promedios de ventas diarias por categoría\n",
        "print(\"\\nPromedio de ventas diarias por categoría:\")\n",
        "print(promedio_ventas_diarias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tL-RyGuHwtZ",
        "outputId": "7d6f8790-9fa6-4385-abe2-67df8316b5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Promedio de ventas diarias por categoría:\n",
            "{'Beauty': 703.5049019607843, 'Clothing': 670.6034482758621, 'Electronics': 716.4611872146119}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**b.3) Vectorización con np.bincount**"
      ],
      "metadata": {
        "id": "vpkWE5tvHSBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar un diccionario vacío para almacenar las ventas diarias por categoría\n",
        "ventas_diarias = {}\n",
        "\n",
        "# Iterar sobre cada categoría\n",
        "for category in categories:\n",
        "    # Filtrar por categoría\n",
        "    mask_categoria = data_csv['Product_Category'] == category\n",
        "    ventas_por_categoria = data_csv['Total_Amount'][mask_categoria]\n",
        "    fechas_categoria = data_csv['Date'][mask_categoria]\n",
        "\n",
        "    # Mapear fechas únicas a índices para acumulación\n",
        "    unique_dates, inverse = np.unique(fechas_categoria, return_inverse=True)\n",
        "    # 'unique_dates' contiene las fechas únicas de la categoría actual.\n",
        "    # 'inverse' mapea cada fecha en 'fechas_categoria' al índice de su fecha única.\n",
        "\n",
        "    # Acumular ventas por fecha utilizando np.bincount\n",
        "    ventas = np.bincount(inverse, weights=ventas_por_categoria)\n",
        "    # 'np.bincount' suma las ventas de 'ventas_por_categoria' para cada índice en 'inverse' (que corresponde a fechas únicas).\n",
        "\n",
        "    # Crear diccionario de ventas diarias con las fechas como claves y las ventas acumuladas como valores\n",
        "    ventas_diarias[category] = dict(zip(unique_dates, ventas))\n",
        "    # 'zip' empareja cada fecha única con el total de ventas correspondientes, y 'dict' convierte esto en un diccionario.\n",
        "\n",
        "# Calcular promedio de ventas diarias por categoría\n",
        "promedio_ventas_diarias = {category: np.mean(list(d.values())) for category, d in ventas_diarias.items()}\n",
        "# Para cada categoría, se calcula el promedio de ventas diarias utilizando 'np.mean' sobre los valores de ventas diarias.\n",
        "\n",
        "# Imprimir el resultado de los promedios de ventas diarias por categoría\n",
        "print(\"\\nPromedio de ventas diarias por categoría:\")\n",
        "print(promedio_ventas_diarias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5GXNcPxHPJl",
        "outputId": "99208c95-b03a-4c03-e954-448e873585ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Promedio de ventas diarias por categoría:\n",
            "{'Beauty': 703.5049019607843, 'Clothing': 670.6034482758621, 'Electronics': 716.4611872146119}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) Identificar las categorías con mayores y menores ventas"
      ],
      "metadata": {
        "id": "PATL2fWENsrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**c.1) Índices de máximo y mínimo con np.argmax y np.argmin**"
      ],
      "metadata": {
        "id": "fYosVnZEIEgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir el diccionario de categorías y ventas a arrays de numpy\n",
        "categories_array = np.array(list(total_ventas_por_categoria.keys()))\n",
        "# 'categories_array' almacena las categorías como un array de numpy, usando las claves del diccionario.\n",
        "ventas_array = np.array(list(total_ventas_por_categoria.values()))\n",
        "# 'ventas_array' almacena las ventas totales por categoría como un array de numpy, usando los valores del diccionario.\n",
        "\n",
        "# Encontrar los índices del máximo y mínimo de ventas usando np.argmax y np.argmin\n",
        "indice_max = np.argmax(ventas_array)\n",
        "# 'np.argmax' devuelve el índice del valor máximo en 'ventas_array', correspondiente a la categoría con mayores ventas.\n",
        "indice_min = np.argmin(ventas_array)\n",
        "# 'np.argmin' devuelve el índice del valor mínimo en 'ventas_array', correspondiente a la categoría con menores ventas.\n",
        "\n",
        "# Obtener las categorías correspondientes a los índices encontrados\n",
        "categoria_max_ventas = categories_array[indice_max]\n",
        "# 'categoria_max_ventas' es la categoría que tiene el valor máximo de ventas.\n",
        "categoria_min_ventas = categories_array[indice_min]\n",
        "# 'categoria_min_ventas' es la categoría que tiene el valor mínimo de ventas.\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"\\nCategoría con mayores ventas: {categoria_max_ventas}\")\n",
        "# Imprime la categoría con el valor máximo de ventas.\n",
        "print(f\"Categoría con menores ventas: {categoria_min_ventas}\")\n",
        "# Imprime la categoría con el valor mínimo de ventas."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJueSy5vIN7j",
        "outputId": "ffdfae62-a988-4d5e-9c72-a329bcec7f16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Categoría con mayores ventas: Electronics\n",
            "Categoría con menores ventas: Beauty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **c.2) Usando ordenación con np.argsort**"
      ],
      "metadata": {
        "id": "qp-ah786IG_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir el diccionario de categorías y ventas a arrays de numpy\n",
        "categories_array = np.array(list(total_ventas_por_categoria.keys()))\n",
        "# 'categories_array' almacena las categorías como un array de numpy, usando las claves del diccionario.\n",
        "ventas_array = np.array(list(total_ventas_por_categoria.values()))\n",
        "# 'ventas_array' almacena las ventas totales por categoría como un array de numpy, usando los valores del diccionario.\n",
        "\n",
        "# Ordenar las ventas de menor a mayor\n",
        "sorted_indices = np.argsort(ventas_array)\n",
        "# 'np.argsort' devuelve los índices que ordenarían 'ventas_array' de menor a mayor. 'sorted_indices' es un array de índices ordenados.\n",
        "\n",
        "# Obtener los índices del menor y mayor valor de ventas\n",
        "indice_min = sorted_indices[0]\n",
        "# El primer índice ('sorted_indices[0]') corresponde a la categoría con el menor valor de ventas.\n",
        "indice_max = sorted_indices[-1]\n",
        "# El último índice ('sorted_indices[-1]') corresponde a la categoría con el mayor valor de ventas.\n",
        "\n",
        "# Obtener las categorías correspondientes a los índices de ventas máximas y mínimas\n",
        "categoria_max_ventas_2 = categories_array[indice_max]\n",
        "# 'categoria_max_ventas_2' es la categoría que tiene el valor máximo de ventas.\n",
        "categoria_min_ventas_2 = categories_array[indice_min]\n",
        "# 'categoria_min_ventas_2' es la categoría que tiene el valor mínimo de ventas.\n",
        "\n",
        "# Imprimir los resultados\n",
        "print(f\"\\nCategoría con mayores ventas: {categoria_max_ventas_2}\")\n",
        "# Imprime la categoría con el valor máximo de ventas.\n",
        "print(f\"Categoría con menores ventas: {categoria_min_ventas_2}\")\n",
        "# Imprime la categoría con el valor mínimo de ventas."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9NmOljrIMOG",
        "outputId": "ad90fb37-b04c-43a5-fbf4-06cb3148c0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Categoría con mayores ventas: Electronics\n",
            "Categoría con menores ventas: Beauty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Manipulación de Datos**\n"
      ],
      "metadata": {
        "id": "ABjXuq1rNvnz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Filtrar los datos por una categoría de producto específica\n"
      ],
      "metadata": {
        "id": "qcuDnRxnNyRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a.1) Uso de máscaras booleanas**"
      ],
      "metadata": {
        "id": "LcEGkArlI3Zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una máscara booleana para filtrar la categoría específica\n",
        "mascara = data_csv['Product_Category'] == 'Clothing'\n",
        "# La 'mascara' es un array de valores booleanos (True o False) que indica si la categoría de cada fila es 'Clothing'.\n",
        "\n",
        "# Aplicar la máscara al conjunto de datos\n",
        "categoria_filtrada = data_csv[mascara]\n",
        "# 'categoria_filtrada' contiene solo las filas del DataFrame 'data_csv' donde la categoría es 'Clothing', filtradas usando la 'mascara'.\n",
        "\n",
        "# Mostrar los primeros 5 resultados filtrados\n",
        "print(\"\\nDatos filtrados para la categoría 'Clothing':\")\n",
        "# Imprime un mensaje que indica que se están mostrando los datos filtrados para la categoría 'Clothing'.\n",
        "print(categoria_filtrada[:5])\n",
        "# Muestra las primeras 5 filas de los datos filtrados de la categoría 'Clothing' en 'categoria_filtrada'."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLLEQgB6I69a",
        "outputId": "009fdd39-4318-4c6a-8f2e-8f3876e3e985"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Datos filtrados para la categoría 'Clothing':\n",
            "[( 2, '2023-02-27', 'CUST002', 'Female', 26, 'Clothing', 2, 500, 1000)\n",
            " ( 4, '2023-05-21', 'CUST004', 'Male', 37, 'Clothing', 1, 500,  500)\n",
            " ( 7, '2023-03-13', 'CUST007', 'Male', 46, 'Clothing', 2,  25,   50)\n",
            " (10, '2023-10-07', 'CUST010', 'Female', 52, 'Clothing', 4,  50,  200)\n",
            " (11, '2023-02-14', 'CUST011', 'Male', 23, 'Clothing', 2,  50,  100)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**a.2) Uso de índices obtenidos con np.where**"
      ],
      "metadata": {
        "id": "dLNn0COgI939"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener los índices donde la categoría coincide\n",
        "indices = np.where(data_csv['Product_Category'] == 'Clothing')[0]\n",
        "# 'np.where' devuelve una tupla con los índices donde la condición es True (es decir, donde la categoría es 'Clothing').\n",
        "# El [0] accede al primer elemento de la tupla que contiene los índices.\n",
        "\n",
        "# Usar los índices para filtrar los datos\n",
        "categoria_filtrada = data_csv[indices]\n",
        "# 'categoria_filtrada' es un DataFrame que contiene solo las filas donde la categoría es 'Clothing',\n",
        "# seleccionadas usando los índices obtenidos con 'np.where'.\n",
        "\n",
        "# Mostrar los primeros 5 resultados filtrados\n",
        "print(\"\\nDatos filtrados para la categoría 'Clothing':\")\n",
        "# Imprime un mensaje indicando que se mostrarán los datos filtrados para la categoría 'Clothing'.\n",
        "print(categoria_filtrada[:5])\n",
        "# Muestra las primeras 5 filas de 'categoria_filtrada' que contiene los datos filtrados por la categoría 'Clothing'."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk5xT7-zJBj2",
        "outputId": "07c585d4-8221-404f-ac4b-65b55fc185a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Datos filtrados para la categoría 'Clothing':\n",
            "[( 2, '2023-02-27', 'CUST002', 'Female', 26, 'Clothing', 2, 500, 1000)\n",
            " ( 4, '2023-05-21', 'CUST004', 'Male', 37, 'Clothing', 1, 500,  500)\n",
            " ( 7, '2023-03-13', 'CUST007', 'Male', 46, 'Clothing', 2,  25,   50)\n",
            " (10, '2023-10-07', 'CUST010', 'Female', 52, 'Clothing', 4,  50,  200)\n",
            " (11, '2023-02-14', 'CUST011', 'Male', 23, 'Clothing', 2,  50,  100)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Realizar operaciones matemáticas sobre los datos"
      ],
      "metadata": {
        "id": "BHWpbx3hN0PG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.1) Usando máscaras booleanas directamente**"
      ],
      "metadata": {
        "id": "z6IU6O2fJLny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar ventas de cada categoría utilizando máscaras\n",
        "ventas_categoria_A = np.sum(data_csv['Total_Amount'][data_csv['Product_Category'] == 'Clothing'])\n",
        "# Filtra las filas del DataFrame 'data_csv' donde la categoría es 'Clothing' y suma las ventas (Total_Amount) correspondientes.\n",
        "\n",
        "ventas_categoria_B = np.sum(data_csv['Total_Amount'][data_csv['Product_Category'] == 'Electronics'])\n",
        "# Filtra las filas del DataFrame 'data_csv' donde la categoría es 'Electronics' y suma las ventas (Total_Amount) correspondientes.\n",
        "\n",
        "# Operaciones matemáticas\n",
        "suma_ventas = ventas_categoria_A + ventas_categoria_B\n",
        "# Suma las ventas de las dos categorías, 'Clothing' y 'Electronics'.\n",
        "\n",
        "resta_ventas = ventas_categoria_A - ventas_categoria_B\n",
        "# Resta las ventas de 'Electronics' de las de 'Clothing'.\n",
        "\n",
        "multiplicacion_ventas = ventas_categoria_A * 1.1  # Incremento del 10%\n",
        "# Multiplica las ventas de 'Clothing' por 1.1 para simular un incremento del 10%.\n",
        "\n",
        "division_ventas = ventas_categoria_A / ventas_categoria_B if ventas_categoria_B != 0 else 0\n",
        "# Divide las ventas de 'Clothing' entre las de 'Electronics', pero si las ventas de 'Electronics' son 0, devuelve 0 para evitar división por cero.\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"\\nSuma de ventas entre Clothing y Electronics: {suma_ventas}\")\n",
        "# Muestra el resultado de la suma de ventas entre 'Clothing' y 'Electronics'.\n",
        "\n",
        "print(f\"Resta de ventas entre Clothing y Electronics: {resta_ventas}\")\n",
        "# Muestra el resultado de la resta de ventas entre 'Clothing' y 'Electronics'.\n",
        "\n",
        "print(f\"Multiplicación de ventas de Clothing por 1.1: {multiplicacion_ventas}\")\n",
        "# Muestra el resultado de multiplicar las ventas de 'Clothing' por 1.1 (incremento del 10%).\n",
        "\n",
        "print(f\"División de ventas entre Clothing y Electronics: {division_ventas}\")\n",
        "# Muestra el resultado de dividir las ventas de 'Clothing' entre las de 'Electronics', o 0 si las ventas de 'Electronics' son 0."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woPkvqzTJZcE",
        "outputId": "6e2085f9-122d-4230-b178-f7e24c6d3288"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Suma de ventas entre Clothing y Electronics: 312485\n",
            "Resta de ventas entre Clothing y Electronics: -1325\n",
            "Multiplicación de ventas de Clothing por 1.1: 171138.0\n",
            "División de ventas entre Clothing y Electronics: 0.9915553997641885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b.2) Usando índices con np.where**"
      ],
      "metadata": {
        "id": "SshMvNDRJQwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir datos a NumPy arrays\n",
        "categorias = np.array(data_csv['Product_Category'])\n",
        "# Convierte la columna 'Product_Category' del DataFrame 'data_csv' a un arreglo de NumPy.\n",
        "\n",
        "ventas_totales = np.array(data_csv['Total_Amount'])\n",
        "# Convierte la columna 'Total_Amount' del DataFrame 'data_csv' a un arreglo de NumPy.\n",
        "\n",
        "# Filtrar ventas de cada categoría con máscaras booleanas\n",
        "ventas_categoria_A = np.sum(ventas_totales[categorias == 'Clothing'])\n",
        "# Filtra las ventas donde la categoría es 'Clothing' y suma las ventas correspondientes.\n",
        "\n",
        "ventas_categoria_B = np.sum(ventas_totales[categorias == 'Electronics'])\n",
        "# Filtra las ventas donde la categoría es 'Electronics' y suma las ventas correspondientes.\n",
        "\n",
        "# Operaciones matemáticas\n",
        "suma_ventas = np.add(ventas_categoria_A, ventas_categoria_B)  # Suma\n",
        "# Suma las ventas de las categorías 'Clothing' y 'Electronics' usando la función np.add.\n",
        "\n",
        "resta_ventas = np.subtract(ventas_categoria_A, ventas_categoria_B)  # Resta\n",
        "# Resta las ventas de 'Electronics' a las de 'Clothing' usando la función np.subtract.\n",
        "\n",
        "multiplicacion_ventas = np.multiply(ventas_categoria_A, 1.1)  # Multiplicación (incremento del 10%)\n",
        "# Multiplica las ventas de 'Clothing' por 1.1 para simular un incremento del 10% usando la función np.multiply.\n",
        "\n",
        "division_ventas = np.divide(ventas_categoria_A, ventas_categoria_B) if ventas_categoria_B != 0 else 0  # División\n",
        "# Divide las ventas de 'Clothing' entre las de 'Electronics' usando np.divide, pero si las ventas de 'Electronics' son 0, devuelve 0 para evitar división por cero.\n",
        "\n",
        "# Mostrar resultados\n",
        "print(f\"\\nSuma de ventas entre Clothing y Electronics: {suma_ventas}\")\n",
        "# Muestra el resultado de la suma de ventas entre 'Clothing' y 'Electronics'.\n",
        "\n",
        "print(f\"Resta de ventas entre Clothing y Electronics: {resta_ventas}\")\n",
        "# Muestra el resultado de la resta de ventas entre 'Clothing' y 'Electronics'.\n",
        "\n",
        "print(f\"Multiplicación de ventas de Clothing por 1.1: {multiplicacion_ventas}\")\n",
        "# Muestra el resultado de multiplicar las ventas de 'Clothing' por 1.1 (incremento del 10%).\n",
        "\n",
        "print(f\"División de ventas entre Clothing y Electronics: {division_ventas}\")\n",
        "# Muestra el resultado de dividir las ventas de 'Clothing' entre las de 'Electronics', o 0 si las ventas de 'Electronics' son 0."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtVvgTINJdQ2",
        "outputId": "cf41194b-a460-4990-9349-ef3f6ef64a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Suma de ventas entre Clothing y Electronics: 312485\n",
            "Resta de ventas entre Clothing y Electronics: -1325\n",
            "Multiplicación de ventas de Clothing por 1.1: 171138.0\n",
            "División de ventas entre Clothing y Electronics: 0.9915553997641885\n",
            "\n",
            "Suma de ventas entre Clothing y Electronics: 312485\n",
            "Resta de ventas entre Clothing y Electronics: -1325\n",
            "Multiplicación de ventas de Clothing por 1.1: 171138.0\n",
            "División de ventas entre Clothing y Electronics: 0.9915553997641885\n"
          ]
        }
      ]
    }
  ]
}